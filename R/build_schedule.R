##' Build an appropriately refined schedule.
##'
##' There are control options (within the \code{Parameters} object)
##' that affect how this function runs, in particular
##' \code{schedule_nsteps} and \code{schedule_eps} control how refined
##' the schedule will end up, and \code{schedule_verbose} controls if
##' details are printed to the screen during construction.
##'
##' @title Build Cohort Schedule
##' @param p Parameters object
##' @param splines A list of interpolating spine functions describing the 
##' initial size distribution for the patch (generated by \code{\link{init_spline}})
##' @param n_init the number of initial cohorts to start with (default = 10)
##' @param ctrl Control object
##' @return A Parameters object, with schedule components set.  The
##' output offspring produced is also available as an attribute
##' \code{birth_rate}.
##' @author Rich FitzJohn
##' @export

build_schedule <- function(p, env = make_environment(parameters = p),
                           ctrl = scm_base_control(),
                           splines = NULL, n_init = 10) {
  p <- validate(p)

  n_spp <- length(p$strategies)
  if (n_spp == 0L || !any(p$is_resident)) {
    stop("Can't build a schedule with no residents")
  }

  eps <- ctrl$schedule_eps
  complete = FALSE

  # generate coarse initial size distribution
  if(!is.null(splines))
    state = lapply(splines, partition_spline, n = n_init)

  # the refine cohorts
  for (i in seq_len(ctrl$schedule_nsteps)) {
    res <- run_scm_error(p, env, ctrl, state)
    net_reproduction_ratios <- res[["net_reproduction_ratios"]]
    split <- lapply(res$err$total, function(x) x > eps)

    # schedule is resolved when no more cohorts are required
    if (!any(unlist(split), na.rm=TRUE)) {
      complete = TRUE
      plant_log_debug("All cohorts below the integration error threshold",
                routine="schedule")
      break
    }

    # schedule from SCM includes initial cohorts
    times <- res$schedule

    # split cohorts
    for (idx in seq_len(n_spp)) {

      # by introduction time
      times[[idx]] <- split_times(times[[idx]], split[[idx]])

      # or by initial size
      if(!is.null(state)) {
        state[[idx]] <- split_state(times[[idx]], split[[idx]],
                                    state[[idx]], splines[[idx]])
      }
    }

    # set schedule for next patch
    p$cohort_schedule_times <- times
    msg <- sprintf("%d: Splitting {%s} times (%s)",
                   i,
                   paste(sapply(split, sum),    collapse=","),
                   paste(sapply(split, length), collapse=","))
    plant_log_debug(msg, routine="schedule", event="split", round=i)
  }

  # record useful attributies
  p$cohort_schedule_ode_times <- res$ode_times
  attr(p, "net_reproduction_ratios") <- net_reproduction_ratios

  plant_log_debug("Maximum number of iterations reached", routine="schedule")

  # return parameters with refined schedule and corresponding initial state
  return(list(parameters = p, state = state, n_steps = i, complete = complete))
}

split_times <- function(times, i) {
  ## Upwind splitting scheme only, which means that we will never
  ## split the last interval [assuming OK for now].  Inefficiently
  ## interleaved with sort().  These issues can change easily enough
  ## later.  The aim is making sure that we don't introduce the same
  ## point twice; one from upstream and one from downstream.
  dt <- diff(times)
  i <- which(i)

  # can't split cohorts introduced in the same time step (inc. t0)
  i <- i[dt[i] > 0]

  sort(c(times, times[i] - dt[i-1]/2))
}

split_state <- function(times, i, state, splines) {
  # Interpolates the intial size distrbution using splines, by halving
  # the size of t0 cohorts with large integration errors. A better scheme
  # would be to split by density (rather than size) but this requires a more
  # complicated splines object (see: scm_spline).

  # can only split cohorts introduced at t0
  i <- which(i)
  i <- i[times[i] == 0]

  if(length(i) == 0)
    return(state)

  size_idx <- attr(splines, 'size_idx')
  domain <- attr(splines, 'domain')

  sizes <- state[size_idx, ]
  ds <- diff(c(sizes, domain[1])) # clamp domain
  new_sizes <- sort(c(sizes, sizes[i-1] + ds[i-1] / 2), decreasing = T)

  # interpolate density, other vars.
  new_state <- partition_spline(splines, sizes = new_sizes)

  return(new_state)
}
